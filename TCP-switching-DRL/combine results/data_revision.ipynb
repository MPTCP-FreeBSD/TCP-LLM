{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data for both clients\n",
    "client1_df = pd.read_csv('/home/sit-research/Downloads/combine results/client1_revised.csv')\n",
    "client2_df = pd.read_csv('/home/sit-research/Downloads/combine results/client2_revised.csv')\n",
    "\n",
    "# Drop the 'RTT' and 'CongestionWindow' columns\n",
    "client1_df = client1_df.drop(columns=['RTT', 'CongestionWindow'])\n",
    "client2_df = client2_df.drop(columns=['RTT', 'CongestionWindow'])\n",
    "\n",
    "# Save the revised data to new CSV files\n",
    "client1_df.to_csv('/home/sit-research/Downloads/combine results/client1_revised.csv', index=False)\n",
    "client2_df.to_csv('/home/sit-research/Downloads/combine results/client2_revised.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "client2_df = pd.read_csv('/home/sit-research/Downloads/combine results/revised data/client2_revised_switch_bbr-cubic.csv')\n",
    "\n",
    "\n",
    "client2_df = client2_df.drop(columns=['RTT', 'CongestionWindow'])\n",
    "\n",
    "# Save the revised data to new CSV files\n",
    "\n",
    "client2_df.to_csv('/home/sit-research/Downloads/combine results/client2_revised.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to the CSV files\n",
    "file_b_path = '/home/sit-research/Downloads/combine results/client1_datapcc-bbr-bbr.csv'\n",
    "file_a_path = '/home/sit-research/Downloads/combine results/client1_latency_bbr_ppc_bbr.csv'\n",
    "# Load the CSV data for file B\n",
    "file_b_df = pd.read_csv(file_b_path)\n",
    "\n",
    "# Load the latency data from file A\n",
    "file_a_df = pd.read_csv(file_a_path)\n",
    "\n",
    "# Extract the seconds from the 'Timestamp' column in file B\n",
    "file_b_df['Second'] = pd.to_datetime(file_b_df['Timestamp']).dt.second\n",
    "\n",
    "# Merge the latency data from file A into file B based on Second\n",
    "file_b_df = file_b_df.merge(file_a_df, on='Second', suffixes=('', '_latency'))\n",
    "\n",
    "# Replace Latency values of 0 in file B with values from file A\n",
    "file_b_df['Latency'] = file_b_df.apply(lambda row: row['Latency_latency'] if row['Latency'] == 0 else row['Latency'], axis=1)\n",
    "\n",
    "# Drop the additional latency column from file A\n",
    "file_b_df = file_b_df.drop(columns=['Latency_latency', 'Second'])\n",
    "\n",
    "# Save the updated data back to file B\n",
    "file_b_df.to_csv('/home/sit-research/Downloads/combine results/client1_revised.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Second'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7922/1862533760.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mclient1_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Second'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient1_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mclient2_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Second'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient2_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Merge the latency data into client data based on 'Second' for each client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mclient1_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient1_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatency_client1_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Second'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_latency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mclient2_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient2_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatency_client2_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Second'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_latency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Replace Latency values of 0 in both client files with values from the latency data for each client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10828\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10829\u001b[0m     ) -> DataFrame:\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10835\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Second'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the CSV files for clients and respective latency data\n",
    "client1_file_path = '/home/sit-research/Downloads/combine results/client1_databbr-cubic-cubic.csv'\n",
    "client2_file_path = '/home/sit-research/Downloads/combine results/client2_data-bbr-cubic-cubic.csv'\n",
    "latency_client1_file_path = '/home/sit-research/Downloads/combine results/client1_latency.csv'\n",
    "latency_client2_file_path = '/home/sit-research/Downloads/combine results/client2_ latency_data.csv'\n",
    "\n",
    "# Load the CSV data for both clients\n",
    "client1_df = pd.read_csv(client1_file_path)\n",
    "client2_df = pd.read_csv(client2_file_path)\n",
    "\n",
    "# Load the latency data for each clientA\n",
    "latency_client1_df = pd.read_csv(latency_client1_file_path)\n",
    "latency_client2_df = pd.read_csv(latency_client2_file_path)\n",
    "\n",
    "# Extract the seconds from the 'Timestamp' column in both client filesA\n",
    "client1_df['Second'] = pd.to_datetime(client1_df['Timestamp']).dt.second\n",
    "client2_df['Second'] = pd.to_datetime(client2_df['Timestamp']).dt.second\n",
    "\n",
    "# Merge the latency data into client data based on 'Second' for each client\n",
    "client1_df = client1_df.merge(latency_client1_df, on='Second', suffixes=('', '_latency'))\n",
    "client2_df = client2_df.merge(latency_client2_df, on='Second', suffixes=('', '_latency'))\n",
    "\n",
    "# Replace Latency values of 0 in both client files with values from the latency data for each client\n",
    "client1_df['Latency'] = client1_df.apply(lambda row: row['Latency_latency'] if row['Latency'] == 0 else row['Latency'], axis=1)\n",
    "client2_df['Latency'] = client2_df.apply(lambda row: row['Latency_latency'] if row['Latency'] == 0 else row['Latency'], axis=1)\n",
    "\n",
    "# Drop the additional latency column from the merged data for each client\n",
    "client1_df = client1_df.drop(columns=['Latency_latency', 'Second'])\n",
    "client2_df = client2_df.drop(columns=['Latency_latency', 'Second'])\n",
    "\n",
    "# Save the updated data back to the respective client filesimport pandas as pd\n",
    "\n",
    "# Paths to the CSV files for clients and respective latency data\n",
    "client1_file_path = '/home/sit-research/Downloads/combine results/client1_databbr-cubic-cubic.csv'\n",
    "client2_file_path = '/home/sit-research/Downloads/combine results/client2_data-bbr-cubic-cubic.csv'\n",
    "latency_client1_file_path = '/home/sit-research/Downloads/combine results/client1_latency.csv'\n",
    "latency_client2_file_path = '/home/sit-research/Downloads/combine results/client2_ latency_data.csv'\n",
    "\n",
    "# Load the CSV data for both clients\n",
    "client1_df = pd.read_csv(client1_file_path)\n",
    "client2_df = pd.read_csv(client2_file_path)\n",
    "\n",
    "# Load the latency data for each clientA\n",
    "latency_client1_df = pd.read_csv(latency_client1_file_path)\n",
    "latency_client2_df = pd.read_csv(latency_client2_file_path)\n",
    "\n",
    "# Extract the seconds from the 'Timestamp' column in both client filesA\n",
    "client1_df['Second'] = pd.to_datetime(client1_df['Timestamp']).dt.second\n",
    "client2_df['Second'] = pd.to_datetime(client2_df['Timestamp']).dt.second\n",
    "\n",
    "# Merge the latency data into client data based on 'Second' for each client\n",
    "client1_df = client1_df.merge(latency_client1_df, on='Second', suffixes=('', '_latency'))\n",
    "client2_df = client2_df.merge(latency_client2_df, on='Second', suffixes=('', '_latency'))\n",
    "\n",
    "# Replace Latency values of 0 in both client files with values from the latency data for each client\n",
    "client1_df['Latency'] = client1_df.apply(lambda row: row['Latency_latency'] if row['Latency'] == 0 else row['Latency'], axis=1)\n",
    "client2_df['Latency'] = client2_df.apply(lambda row: row['Latency_latency'] if row['Latency'] == 0 else row['Latency'], axis=1)\n",
    "\n",
    "# Drop the additional latency column from the merged data for each client\n",
    "client1_df = client1_df.drop(columns=['Latency_latency', 'Second'])\n",
    "client2_df = client2_df.drop(columns=['Latency_latency', 'Second'])\n",
    "\n",
    "# Save the updated data back to the respective client files\n",
    "client1_df.to_csv('/home/sit-research/Downloads/combine results/client1_revised.csv', index=False)\n",
    "client2_df.to_csv('/home/sit-research/Downloads/combine results/client2_revised.csv', index=False)\n",
    "client1_df.to_csv('/home/sit-research/Downloads/combine results/client1_revised.csv', index=False)\n",
    "client2_df.to_csv('/home/sit-research/Downloads/combine results/client2_revised.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from CSV file\n",
    "df = pd.read_csv(\"/home/sit-research/Downloads/combine results/client1_data.csv\")\n",
    "\n",
    "# Extract the \"Latency\" column\n",
    "latency_column = df[\"Latency\"]\n",
    "\n",
    "# Create a new dataframe with just the \"Latency\" column\n",
    "latency_df = pd.DataFrame(latency_column, columns=[\"Latency\"])\n",
    "\n",
    "# Save the new dataframe to a CSV file\n",
    "latency_df.to_csv(\"latency_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError: ''Second''\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the CSV files for clients and respective latency data\n",
    "client1_file_path = '/home/sit-research/Downloads/combine results/client1_databbr-cubic-cubic.csv'\n",
    "client2_file_path = '/home/sit-research/Downloads/combine results/client2_data-bbr-cubic-cubic.csv'\n",
    "latency_client1_file_path = '/home/sit-research/Downloads/combine results/client1_latency.csv'\n",
    "latency_client2_file_path = '/home/sit-research/Downloads/combine results/client2_ latency_data.csv'\n",
    "\n",
    "try:\n",
    "    # Load the CSV data for both clients\n",
    "    client1_df = pd.read_csv(client1_file_path)\n",
    "    client2_df = pd.read_csv(client2_file_path)\n",
    "\n",
    "    # Load the latency data for each client\n",
    "    latency_client1_df = pd.read_csv(latency_client1_file_path)\n",
    "    latency_client2_df = pd.read_csv(latency_client2_file_path)\n",
    "\n",
    "    # Extract the seconds from the 'Timestamp' column in both client files\n",
    "    client1_df['Second'] = pd.to_datetime(client1_df['Timestamp']).dt.second\n",
    "    client2_df['Second'] = pd.to_datetime(client2_df['Timestamp']).dt.second\n",
    "\n",
    "    # Merge the latency data into client data based on 'Second' for each client\n",
    "    client1_df = client1_df.merge(latency_client1_df, on='Second', suffixes=('', '_latency'))\n",
    "    client2_df = client2_df.merge(latency_client2_df, on='Second', suffixes=('', '_latency'))\n",
    "\n",
    "    # Replace Latency values of 0 in both client files with values from the latency data for each client\n",
    "    client1_df['Latency'] = client1_df.apply(lambda row: row['Latency_latency'] if row['Latency'] == 0 else row['Latency'], axis=1)\n",
    "    client2_df['Latency'] = client2_df.apply(lambda row: row['Latency_latency'] if row['Latency'] == 0 else row['Latency'], axis=1)\n",
    "\n",
    "    # Drop the additional latency column from the merged data for each client\n",
    "    client1_df = client1_df.drop(columns=['Latency_latency', 'Second'])\n",
    "    client2_df = client2_df.drop(columns=['Latency_latency', 'Second'])\n",
    "\n",
    "    # Save the updated data back to the respective client files\n",
    "    client1_df.to_csv('/home/sit-research/Downloads/combine results/client1_revised.csv', index=False)\n",
    "    client2_df.to_csv('/home/sit-research/Downloads/combine results/client2_revised.csv', index=False)\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: '{e}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the CSV files for clients and respective latency data\n",
    "client1_file_path = '/home/sit-research/Downloads/combine results/client1_databbr-cubic-cubic.csv'\n",
    "client2_file_path = '/home/sit-research/Downloads/combine results/client2_data-bbr-cubic-cubic.csv'\n",
    "latency_client1_file_path = '/home/sit-research/Downloads/combine results/client1_latency.csv'\n",
    "latency_client2_file_path = '/home/sit-research/Downloads/combine results/client2_ latency_data.csv'\n",
    "\n",
    "try:\n",
    "    # Load the CSV data for both clients\n",
    "    client1_df = pd.read_csv(client1_file_path)\n",
    "    client2_df = pd.read_csv(client2_file_path)\n",
    "\n",
    "    # Load the latency data for each client\n",
    "    latency_client1_df = pd.read_csv(latency_client1_file_path)\n",
    "    latency_client2_df = pd.read_csv(latency_client2_file_path)\n",
    "\n",
    "    # Merge the latency data into client data\n",
    "    client1_df['Latency'] = latency_client1_df['Latency']\n",
    "    client2_df['Latency'] = latency_client2_df['Latency']\n",
    "\n",
    "    # Save the updated data back to the respective client files\n",
    "    client1_df.to_csv('/home/sit-research/Downloads/combine results/client1_revised.csv', index=False)\n",
    "    client2_df.to_csv('/home/sit-research/Downloads/combine results/client2_revised.csv', index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
