{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: /home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/client1 _bbr_full.csv\n",
      "Combined data saved to '/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/combined_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of filenames\n",
    "csv_files = [\n",
    "    '/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/client1 _bbr_full.csv',\n",
    "    '/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/client1_cubic_full.csv',\n",
    "    '/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/client1_pcc.csv',\n",
    "    '/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/client2_bbr_switch_cubic.csv',\n",
    "    '/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/client2_pcc.csv',\n",
    "    '/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/client2_pcc_switch_bbr.csv'\n",
    "]\n",
    "\n",
    "# Function to extract CCA from the filename\n",
    "def get_cca_from_filename(filename, switch_time=40):\n",
    "    if 'switch' in filename:\n",
    "        if 'bbr_switch_cubic' in filename:\n",
    "            return 'BBR', 'CUBIC', switch_time\n",
    "        elif 'pcc_switch_bbr' in filename:\n",
    "            return 'PCC', 'BBR', switch_time\n",
    "    elif 'bbr' in filename:\n",
    "        return 'BBR', None, None\n",
    "    elif 'cubic' in filename:\n",
    "        return 'CUBIC', None, None\n",
    "    elif 'pcc' in filename:\n",
    "        return 'PCC', None, None\n",
    "    else:\n",
    "        return 'UNKNOWN', None, None\n",
    "\n",
    "# Initialize an empty list to hold DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the list of CSV files and read each one into a DataFrame\n",
    "for file in csv_files:\n",
    "    if os.path.exists(file):\n",
    "        df = pd.read_csv(file)\n",
    "        if 'Timestamp' not in df.columns:\n",
    "            print(f\"Warning: 'Timestamp' column not found in {file}. Skipping this file.\")\n",
    "            continue\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])  # Ensure Timestamp is in datetime format\n",
    "        df['time'] = (df['Timestamp'] - df['Timestamp'].min()).dt.total_seconds()  # Create a 'time' column in seconds\n",
    "        cca1, cca2, switch_time = get_cca_from_filename(file)\n",
    "        if cca2 is None:\n",
    "            df['CCA'] = cca1\n",
    "        else:\n",
    "            df['CCA'] = [cca1 if t <= switch_time else cca2 for t in df['time']]\n",
    "        dataframes.append(df)\n",
    "    else:\n",
    "        print(f\"File not found: {file}\")\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame if dataframes list is not empty\n",
    "if dataframes:\n",
    "    combined_data = pd.concat(dataframes, ignore_index=True)\n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    combined_data.to_csv('/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/combined_data.csv', index=False)\n",
    "    print(\"Combined data saved to '/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/combined_data.csv'\")\n",
    "else:\n",
    "    print(\"No valid files were found. Please check the file paths and content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after handling:\n",
      "Timestamp      0\n",
      "Throughput     0\n",
      "LossRate       0\n",
      "Latency        0\n",
      "SendingRate    0\n",
      "time           0\n",
      "CCA            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_369022/299680828.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data[col].fillna(combined_data[col].mean(), inplace=True)\n",
      "/tmp/ipykernel_369022/299680828.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data[col].fillna(combined_data[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values for numerical columns with mean\n",
    "for col in combined_data.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    combined_data[col].fillna(combined_data[col].mean(), inplace=True)\n",
    "\n",
    "# Fill missing values for categorical columns with mode\n",
    "for col in combined_data.select_dtypes(include=['object']).columns:\n",
    "    combined_data[col].fillna(combined_data[col].mode()[0], inplace=True)\n",
    "\n",
    "# Verify if all missing values are handled\n",
    "missing_values_post = combined_data.isnull().sum()\n",
    "print(\"Missing values after handling:\")\n",
    "print(missing_values_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Timestamp  Throughput   LossRate       Latency  SendingRate  \\\n",
      "0 2024-05-30 07:31:40   -2.063979  16.292751  8.473640e-17    -3.328244   \n",
      "1 2024-05-30 07:31:41   -0.170823   0.580359  8.473640e-17    -0.282757   \n",
      "2 2024-05-30 07:31:42    0.504422  -0.011853  8.473640e-17    -0.916587   \n",
      "3 2024-05-30 07:31:43    1.590342  -0.047357  8.473640e-17    -0.755940   \n",
      "4 2024-05-30 07:31:44    1.758314  -0.060487  8.473640e-17    -0.867777   \n",
      "\n",
      "       time    CCA  \n",
      "0 -1.712318  CUBIC  \n",
      "1 -1.680774  CUBIC  \n",
      "2 -1.649230  CUBIC  \n",
      "3 -1.617685  CUBIC  \n",
      "4 -1.586141  CUBIC  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select numerical columns for standardization\n",
    "numerical_cols = combined_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize numerical columns\n",
    "scaler = StandardScaler()\n",
    "combined_data[numerical_cols] = scaler.fit_transform(combined_data[numerical_cols])\n",
    "\n",
    "# Display the first few rows after standardization\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Timestamp  Throughput   LossRate       Latency  SendingRate  \\\n",
      "0 2024-05-30 07:31:40   -2.063979  16.292751  3.151223e-17    -3.328244   \n",
      "1 2024-05-30 07:31:41   -0.170823   0.580359  3.151223e-17    -0.282757   \n",
      "2 2024-05-30 07:31:42    0.504422  -0.011853  3.151223e-17    -0.916587   \n",
      "3 2024-05-30 07:31:43    1.590342  -0.047357  3.151223e-17    -0.755940   \n",
      "4 2024-05-30 07:31:44    1.758314  -0.060487  3.151223e-17    -0.867777   \n",
      "\n",
      "       time    CCA  \n",
      "0 -1.712318  CUBIC  \n",
      "1 -1.680774  CUBIC  \n",
      "2 -1.649230  CUBIC  \n",
      "3 -1.617685  CUBIC  \n",
      "4 -1.586141  CUBIC  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select numerical columns for standardization\n",
    "numerical_cols = combined_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize numerical columns\n",
    "scaler = StandardScaler()\n",
    "combined_data[numerical_cols] = scaler.fit_transform(combined_data[numerical_cols])\n",
    "\n",
    "# Display the first few rows after standardization\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "split_index = int(0.8 * len(combined_data))\n",
    "train_data = combined_data.iloc[:split_index]\n",
    "test_data = combined_data.iloc[split_index:]\n",
    "\n",
    "# Save training data to CSV\n",
    "train_data.to_csv('/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/train_data.csv', index=False)\n",
    "\n",
    "# Save testing data to CSV\n",
    "test_data.to_csv('/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CongestionControlEnv(gym.Env):\n",
    "    def __init__(self, data, thresholds):\n",
    "        super(CongestionControlEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.thresholds = thresholds\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(4,), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.current_step = 0\n",
    "        self.state = None\n",
    "        self.current_cca = 'default'\n",
    "        self.available_ccas = ['cca1', 'cca2', 'cca3']\n",
    "\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.state = self.data.iloc[self.current_step][['Throughput', 'Latency', 'LossRate', 'SendingRate']].values\n",
    "        self.current_cca = 'default'\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 1:\n",
    "            best_cca = self.evaluate_best_cca()\n",
    "            if best_cca != self.current_cca:\n",
    "                self.current_cca = best_cca\n",
    "                print(f\"Switched to congestion control algorithm: {self.current_cca}\")\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data)\n",
    "        if not done:\n",
    "            self.state = self.data.iloc[self.current_step][['Throughput', 'Latency', 'LossRate', 'SendingRate']].values\n",
    "        else:\n",
    "            self.state = None\n",
    "\n",
    "        reward = self._calculate_reward(action)\n",
    "        info = {'action': action, 'cca': self.current_cca}\n",
    "\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def evaluate_best_cca(self):\n",
    "        current_state = self.state\n",
    "        historical_data = self.get_historical_data()\n",
    "\n",
    "        if historical_data is not None and len(historical_data) > 0:\n",
    "            combined_state = 0.8 * current_state + 0.2 * np.mean(historical_data, axis=0)\n",
    "        else:\n",
    "            combined_state = current_state\n",
    "\n",
    "        best_cca = self.choose_best_cca_from_evaluation(combined_state)\n",
    "        return best_cca\n",
    "\n",
    "    def choose_best_cca_from_evaluation(self, combined_state):\n",
    "        weights = {'Throughput': 0.7, 'Latency': 0.2, 'LossRate': 0.1}\n",
    "        cca_scores = {cca: sum(weights[metric] * combined_state[i] for i, metric in enumerate(weights)) for cca in self.available_ccas}\n",
    "        best_cca = max(cca_scores, key=cca_scores.get)\n",
    "        return best_cca\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        if self.state is None:  # Handle case where state is None\n",
    "            return 0  # Return zero reward if state is None\n",
    "        disparities = np.abs(self.state - self.data.iloc[self.current_step-1][['Throughput', 'Latency', 'LossRate', 'SendingRate']].values)\n",
    "        reward = 0\n",
    "        if np.any(disparities > self.thresholds):\n",
    "            reward += np.log10(0.059)  # High disparities reward\n",
    "        else:\n",
    "            reward -= np.log10(0.01)  # Low disparities penalty\n",
    "        if action == 1:\n",
    "            reward += np.log10(0.05) # Switching penalty\n",
    "        return reward\n",
    "\n",
    "\n",
    "    def get_historical_data(self):\n",
    "        return self.data.iloc[:self.current_step][['Throughput', 'Latency', 'LossRate', 'SendingRate']].values\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_shape, action_space):\n",
    "        self.state_shape = state_shape\n",
    "        self.action_space = action_space\n",
    "        self.model = self.build_model()\n",
    "        self.replay_buffer = []\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.loss_history = []\n",
    "        self.accuracy_history = []\n",
    "        self.save_path = '/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/my_dqn_model2.h5'  # Specify your desired save path here\n",
    "\n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Dense(64, activation='relu', input_shape=self.state_shape),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(self.action_space, activation='linear')\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_space)\n",
    "        state_tensor = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "        act_values = self.model.predict(state_tensor)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.replay_buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def train(self, batch_size):\n",
    "        if len(self.replay_buffer) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.replay_buffer, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                next_state_tensor = tf.convert_to_tensor(next_state, dtype=tf.float32)\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state_tensor)[0])\n",
    "            state_tensor = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "            target_f = self.model.predict(state_tensor)\n",
    "            target_f[0][action] = target\n",
    "            history = self.model.fit(state_tensor, target_f, epochs=1, verbose=0)\n",
    "            self.loss_history.append(history.history['loss'][0])\n",
    "            self.accuracy_history.append(history.history['accuracy'][0])\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.save(self.save_path)\n",
    "\n",
    "    def load_model(self, file_path):\n",
    "        self.model = tf.keras.models.load_model(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sit-research/anaconda3/envs/tfenv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-08-13 16:47:00.736583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7057 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_log.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[1;32m     16\u001b[0m     fieldnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_reward\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mcsv\u001b[49m\u001b[38;5;241m.\u001b[39mDictWriter(csvfile, fieldnames\u001b[38;5;241m=\u001b[39mfieldnames)\n\u001b[1;32m     18\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriteheader()\n\u001b[1;32m     20\u001b[0m rewards \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPISODES =1000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Example dataset, replace with actual data\n",
    "combined_data = np.random.rand(100, 4)\n",
    "combined_data = pd.DataFrame(combined_data, columns=['Throughput', 'Latency', 'LossRate', 'SendingRate'])\n",
    "\n",
    "env = CongestionControlEnv(data=combined_data, thresholds=[0.1, 0.1, 0.1, 0.1])\n",
    "state_shape = (env.observation_space.shape[0],)\n",
    "action_space = env.action_space.n\n",
    "agent = DQNAgent(state_shape, action_space)\n",
    "\n",
    "# Initialize CSV file for logging\n",
    "with open('training_log.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['episode', 'total_reward', 'loss', 'accuracy']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "rewards = []\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "# Plotting setup\n",
    "plt.ion()\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "reward_line, = axs[0].plot([], [], label='Reward')\n",
    "loss_line, = axs[1].plot([], [], label='Loss')\n",
    "accuracy_line, = axs[2].plot([], [], label='Accuracy')\n",
    "\n",
    "axs[0].set_xlabel('Episode')\n",
    "axs[0].set_ylabel('Total Reward')\n",
    "axs[0].set_title('Training Rewards')\n",
    "axs[1].set_xlabel('Episode')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_title('Training Loss')\n",
    "axs[2].set_xlabel('Episode')\n",
    "axs[2].set_ylabel('Accuracy')\n",
    "axs[2].set_title('Training Accuracy')\n",
    "\n",
    "def update_plot():\n",
    "    reward_line.set_xdata(range(len(rewards)))\n",
    "    reward_line.set_ydata(rewards)\n",
    "    axs[0].relim()\n",
    "    axs[0].autoscale_view()\n",
    "\n",
    "    loss_line.set_xdata(range(len(losses)))\n",
    "    loss_line.set_ydata(losses)\n",
    "    axs[1].relim()\n",
    "    axs[1].autoscale_view()\n",
    "\n",
    "    accuracy_line.set_xdata(range(len(accuracies)))\n",
    "    accuracy_line.set_ydata(accuracies)\n",
    "    axs[2].relim()\n",
    "    axs[2].autoscale_view()\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.01)\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_shape[0]])\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        if next_state is not None:\n",
    "            next_state = np.reshape(next_state, [1, state_shape[0]])\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "        total_reward += reward\n",
    "    agent.train(BATCH_SIZE)\n",
    "    rewards.append(total_reward)\n",
    "    losses.append(np.mean(agent.loss_history[-BATCH_SIZE:]))\n",
    "    accuracies.append(np.mean(agent.accuracy_history[-BATCH_SIZE:]))\n",
    "\n",
    "    with open('training_log.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writerow({'episode': episode + 1, 'total_reward': total_reward, 'loss': losses[-1], 'accuracy': accuracies[-1]})\n",
    "\n",
    "    update_plot()\n",
    "    print(f\"Episode: {episode + 1}, Total Reward: {total_reward}, Loss: {losses[-1]}, Accuracy: {accuracies[-1]}\")\n",
    "\n",
    "# Save the trained model\n",
    "save_path = '/home/sit-research/Desktop/DRL/combine results/revised data/DRL Data/my_dqn_model2.h5'\n",
    "agent.model.save(save_path)\n",
    "\n",
    "plt.ioff()\n",
    "plt.savefig('training_metrics.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
